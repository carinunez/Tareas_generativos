{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carinunez/Tareas_generativos/blob/main/Tarea1_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APEcMpP3ru2r"
      },
      "source": [
        "# Tarea 1: Modelos Autorregresivos\n",
        "\n",
        "### MDS7203 Modelos Generativos Profundos\n",
        "\n",
        "**Nombre:**\n",
        "- Carolina Nuñez\n",
        "- Hecmar Taucare\n",
        "\n",
        "**Fecha de entrega:**\n",
        "\n",
        "Dado que la arquitectura Transformer es una de las dos arquitecturas específicas que se verán a lo largo del curso (la otra es la arquitectura U-Net), es importante asegurarse de entenderla bien. Por este motivo, esta primera tarea tendrá varias preguntas conceptuales que buscan evaluar si se entienden bien algunos detalles importantes de la arquitectura Transformer.\n",
        "\n",
        "Algunas instrucciones generales:\n",
        "- Se pueden utilizar de manera libre herramientas como ChatGPT y Claude, entre otras.\n",
        "- Para la entrega, no es necesario un informe, este archivo es suficiente.\n",
        "- Se debe entregar el documento con todas las celdas ejecutadas.\n",
        "- Se recomienda correr la tarea en GPU (usando Google Colab o una GPU local).\n",
        "- La tarea tiene 3 partes, y cada parte vale lo mismo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDFZAn8Qru2t"
      },
      "source": [
        "## Parte 1 (preguntas conceptuales)\n",
        "\n",
        "### Modelos autorregresivos generales\n",
        "- ¿Qué son los tokens especiales dentro de un vocabulario? Nombre al menos 5 junto a su función.\n",
        "> **Respuesta:**\n",
        "  Tokens especiales: son tokens añadidos durante el proceso de tokenización para cumplir un a función en particular, y son utilizados como marcadores.\n",
        "  1. **\\<PAD>** : utilizado como \"relleno\", para forzar el largo de una secuencia cuando no se logra el tamaño adecuado.\n",
        "  2. **\\<BOS>** : token agregado al inicio de cada secuencia\n",
        "  3. **\\<EOS>** : token agregado al final de cada secuencia\n",
        "  4. **\\<UNK>** : utilizado para representar tokens desconocidos,ie. fuera del vocabulario extendido.\n",
        "  5. **\\<MASK>** : utilizado para enmascarar/tapar un token. Se suele utilizar en BERT.\n",
        "\n",
        "- Los modelos autorregresivos se entrenan siguiendo el enfoque de máxima verosimilitud. Sin embargo, durante el entrenamiento, es usual normalizar la verosimilitud de una secuencia por su largo, ¿por qué se hace esto?\n",
        "> **Respuesta:**\n",
        "Como la log verosimilitud se define como una suma, las secuencias de mayor longitud dominarían esta función, entonces para evitar este problema se normaliza por el largo de la secuencia, dándoles igual importancia a todas las secuencias. De esa forma, si tengo dos respuestass correctas a una pregunta (una corta y otra larga), normalizar hace que estas sean igual de buenas para el modelo, sin priorizar una por sobre otra. Pues si no normalizo, la respuesta larga se tiene mayor función de pérdida por tener más tokens.\n",
        "\n",
        "\n",
        "- ¿Por qué los modelos neuronales por lo general no aplican la función Softmax en la salida, incluso cuando se está buscando aprender un vector de probabilidades (que permite definir una distribución sobre el vocabulario para predecir el siguiente token)? ¿Cómo se relaciona esto con la idea de temperatura usada durante la inferencia?\n",
        "> **Respuesta:**\n",
        "  No se suele aplicar la función Softmax, pues esta se incluye de forma implícita dentro de la función de pérdida Cross Entropy, que toma los logits  y aplica softmax para luego calcular la función de pérdida.\n",
        "\n",
        "  Además aplicarla en la salida sería redundante y podría generar inestabilidades. Es por esto que nacen ciertas medidas de normalización, tanto para mejorar la estabilidad del modelo como para tener una salida de probabilidad más flexible, una de ellas es la temperatura:\n",
        "  - Baja temperatura *(T<1)* : la distribución de prob de los tokens tiene poca dispersión, por lo que los tokens de mayor prob suelen ser los escogidos.\n",
        "  - Alta temperatura *(T>1)* : al distribución se vuelve cada vez más homogénea, por lo que se le termina dando más peso a los tokens menos probables. Esto le da mayor \"creatividad\" al modelo para elegir tokens.\n",
        "\n",
        "   <!-- en la cual a menor valor de temperatura *(T<1)*  se seleccionaran las secuencias que mayor probabilidad tienen de ser las correctas dadas las secuencias anteriores (menor dispersión en la distribución de tokens) , es decir el top de las mejores. Mientras que con mayor temperatura *(T>1)* se le da mayor \"creatividad\" al modelo para elegir secuencias secundarias *(mayor dispersión en la probabilidad de tokens)*, pero que son buenas respuestas. -->\n",
        "   Además, no aplicar la softmax resulta más eficiente y estable, sino en la optimización el modelo podría explotar o no converger a un mínimo local.\n",
        "\n",
        "\n",
        "- ¿Cuál es la función de la temperatura al generar secuencias? ¿Qué diferencia hay entre una temperatura alta y una temperatura baja?\n",
        "> **Respuesta:**\n",
        "  La **temperatura** es un parámetro que ajusta la aleatoriedad de las predicciones del modelo durante la generación de texto. Se aplica a los *logits* antes de convertirlos a dist de prob\n",
        "\n",
        "  $$\n",
        "  P_i = \\frac{e^{z_i / T}}{\\sum_j e^{z_j / T}}\n",
        "  $$\n",
        "\n",
        "  Donde:\n",
        "\n",
        "  - $( z_i )$: logit del token \\( i \\)  \n",
        "  - $( T)$: temperatura (escala)  \n",
        "  - $( P_i)$: probabilidad del token \\( i \\)\n",
        "\n",
        "  **Interpretación del efecto de T:**\n",
        "\n",
        "  - Si \\( T = 1 \\), se usa softmax normal.  \n",
        "  - Si \\( T < 1 \\), la distribución se vuelve más “picuda” → más determinismo. Se le da mayor peso a los tokens más probables al ser más concentrada.\n",
        "  - Si \\( T > 1 \\), la distribución se aplana → más creatividad. Se le da más peso a los tokens menos probables, por lo que aumenta la aleatoriedad en las respuestas.\n",
        "\n",
        "<!-- La temperatura permite controlar que tan creativas o precisas serán las secuencias creadas en la inferencia. Una temperatura alta le dará similar probabilidad a todos los tokens suavizando la distribución, mientras que una temperatura baja es bastante determinista pues se le da mayor peso a los tokens con mayor probabilidad *(concentrando o dandole mas peso a las secuencias que por si son las más probables de ser las mejores de todas)*, por lo que, en solicitudes de hacer poemas por ejemplo:\n",
        "La temperatura alta servirá para ajustar la respuesta al elegir secuencias secundarias -> mayor creatividad en labores artísticas.\n",
        "Mientras que para labores matemáticas el modelo tendrá la mejor solución posible a temperatura baja, dado que la matemática posee una lógica subyacente que es inalterable en la mayoria de los casos, tendiendo a una solución determinista -->\n",
        "\n",
        "\n",
        "### Arquitectura GPT\n",
        "- ¿Por qué se proyecta una misma entrada en 3 matrices ($Q$, $K$ y $V$) para el cálculo de atención? ¿Por qué no usar la propia entrada como vectores de query, key y value?\n",
        "> **Respuesta:**\n",
        "  Las 3 proyecciones entregan distinta info acerca de los tokens entregados. Esto permite que los tokens sean capaces de poner atención a otros tokens y cuantificarla. Entonces, al multiplicarlas es posible obtener relaciones entre tokens y se fuerza a que el modelo aprenda de la información en otra dimensión.\n",
        "  Al paralelizar lo anterior y usar varias capas de Self-Attention, el modelo puede aprender diferentes habilidades, tales como reconocer estructuras gramaticales, operaciones lógicas, formas en las que se relacionan las palabras y formas de responder.\n",
        "\n",
        "  <!-- La matriz Q representa al token actual, K los tokens a los que se les presta atención y V la info que entrega el token. Entonces, al multiplicarlas es posible obtener relaciones entre tokens y se fuerza a que el modelo aprenda de la información en otra dimensión.\n",
        "  Al paralelizar lo anterior y usar varias capas de selfattention, el modelo puede aprender diferentes habilidades, tales como reconocer estructura gramatical, operaciones lógicas, formas en las que se relacionan las palabras y formas de responder\n",
        "\n",
        "  Antes de explicar lo anterior cabe destacar de que cada una de las matrices inician con pesos aleatorios, porque si fueran la misma matriz el modelo aprendería lo mismo. Cada una de estas posee cierta labor dentro del aprendizaje tanto del contexto de los tokens dentro del vocabulario, como la relación entre los tokens. Al multiplicar las matrices entre ellas,las cuales son resultado de entre ellas *(utilizando el producto punto como medida de similitud,)*, se pueden observar relaciones entre tokens y al multiplicar las matrices se fuerza a que el modelo aprenda de la información en otra dimensión (proyección), distintas proyecciones implican diferentes relaciones y puntos de vista diferentes, al paralelizar lo anterior y usar varias capas de selfattention, el modelo puede aprender diferentes habilidades, tales como reconocer estructura gramatical, operaciones lógicas, formas en las que se relacionan las palabras y formas de responder.. -->\n",
        "\n",
        "  En particular, la Atención se calcula de la siguiente forma:\n",
        "  $$\n",
        "  \\text{Attention}(Q, K, V) = \\text{softmax} \\left( \\frac{Q K^\\top}{\\sqrt{p}} \\right) \\cdot V\n",
        "  $$\n",
        "\n",
        "  Las tres matrices anteriores corresponden cada una a\n",
        "  - Q Query(matriz de consulta)\n",
        "  - K Key (clave)\n",
        "  - V Value (valor)\n",
        "  El producto punto entre Q y K permite medir la similitud entre tokens, y con eso se calcula qué tan relevante es cada token con respecto a los demás. Este resultaso se pondera por los valores en V, permitiendo al modelo enfocarse directamente forma dinámica a aprender en diferentes partes de la secuencia de forma paralela.\n",
        "  <!-- Estas distintas proyecciones hacen que el modelo aprenda relaciones desde múltiples puntos de vista (gramática, sintaxis, semántica, etc.), especialmente cuando se usan múltiples cabezas de atención en paralelo. -->\n",
        "\n",
        " Usar estas proyecciones directamente como inputs le quitaría flexibilidad al modelo, ya que no  sepodría generar distintas representaciones de Q,K,V. Junto con ello, se limita la capacidad de aprendizaje del modelo, las operaciones serían simétricas.\n",
        "\n",
        "\n",
        "- Al hacer el cálculo de atención, ¿por qué se normaliza el producto punto por la dimensión de los vectores de query y key?\n",
        "> **Respuesta:**\n",
        "  Se normaliza para evitar que explote la optimización y para prevenir que valores muy altos junto a las dimensiones altas de los vectores key y query dificulten el aprendizaje. Además, normalizamos porque esperamos que la varianza esté acotada, i.e los datos no tengan gran dispersión.\n",
        "  Al dividir  $\\sqrt{p}$, se reduce la varianza del producto escalar, estabilizando los valores antes del softmax y asegurando un entrenamiento más eficiente y estable.\n",
        "  Esto permite que la atención funcione correctamente incluso con vectores de alta dimensión\n",
        "\n",
        "- ¿Cuál es la función del masking causal al calcular self-attention? ¿Por qué no se aplica masking causal en el modelo BERT? ¿Qué tipo de masking utiliza BERT?\n",
        "> **Respuesta:**\n",
        "  El masking causal evita que el token aprenda información futura y solo se entrene con información pasada (causalidad), lo cual es útil para modelos autoregresivos como GPT. Para ello se aplica una máscara triangular superior, que bloquea la atención hacia tokens posteriores, manteniendo la causalidad en la generación.\n",
        "  \n",
        "  En cambio, modelos como BERT, que son bidireccionales, no usan este tipo de máscara porque su objetivo es distinto. En vez de generar texto secuencialmente, BERT se entrena enmascarando tokens al azar dentro de la secuencia, y el modelo ldebe predecirlos usando tanto el contexto anterior como el posterior. Este tipo de masking se llama *masked language modeling*.\n",
        "  Esto le permite aprender una representación más completa del texto, lo que lo hace útil para tareas como clasificación, QA o detección de entidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VQb3-Qru2u"
      },
      "source": [
        "## Parte 2 (instruction fine tuning)\n",
        "\n",
        "Esta parte tiene dos objetivos principales:\n",
        "- Entender cómo se realiza instruction fine tuning (IFT). Esto busca evaluar que se entiende el proceso de entrenamiento de un LLM.\n",
        "- Implementar KV caching para acelerar la inferencia de un LLM. Esto busca evaluar que se entiende el proceso de generación de un LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGYiDPRXru2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f03c1b5d-0082-4054-f5e6-6583c9e79cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "import torch\n",
        "import time\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import json\n",
        "import tiktoken\n",
        "import gdown\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxVEk93ru2v"
      },
      "source": [
        "Se comenzará descargando los datos de entrenamiento y los parámetros de un modelo ya pre-entrenado (GPT 2):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBv36uq3ru2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "collapsed": true,
        "outputId": "0649265d-fdb1-472a-e13a-1adaefd28549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wky_HjclMRrg92bQu-xSp86PrdxLzlZE\n",
            "To: /content/data.json\n",
            "100%|██████████| 204k/204k [00:00<00:00, 56.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM\n",
            "From (redirected): https://drive.google.com/uc?id=1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM&confirm=t&uuid=656626c0-7c52-442d-b9f1-549bedb95214\n",
            "To: /content/gpt2.pt\n",
            "100%|██████████| 1.73G/1.73G [00:22<00:00, 76.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt2.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "datos = 'https://drive.google.com/file/d/1Wky_HjclMRrg92bQu-xSp86PrdxLzlZE/view?usp=share_link'\n",
        "output_path = 'data.json'\n",
        "gdown.download(datos, output_path, quiet=False,fuzzy=True)\n",
        "\n",
        "modelo = 'https://drive.google.com/file/d/1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM/view?usp=share_link'\n",
        "#modelo = 'https://drive.google.com/file/d/1cKlSCeTbzCO8QEF_juZ6qbxjUf-kzWD0/view?usp=sharing'\n",
        "output_path = 'gpt2.pt'\n",
        "gdown.download(modelo, output_path, quiet=False,fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r8NSauxc_pqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmEvQ2qru2v"
      },
      "source": [
        "### Tokenización\n",
        "\n",
        "Para la tokenización, se utilizará la librería `tiktoken` desarrollada por OpenAI. Esta librería contiene el tokenizador usado por el modelo GPT 2, al cual se le aplicará instruction fine tuning.\n",
        "\n",
        "- ¿Cuál es el tokenizador que utiliza GPT 2? Indique sus principales ventajas sobre tokenizar palabra a palabra.\n",
        "\n",
        "> **Respuesta:**\n",
        "  GPT 2 utiliza BPE (Byte Pair Encoding), este algortimo agrupa letras generando subpalabras que suelen repetirse.\n",
        "  \\\\\n",
        "  VENTAJAS :\n",
        "  - Al no agrupar por palabras completas, se evita el problema de tener que lidiar con palabras nuevas que no estaban en el vocabulario.\n",
        "  - Vocabulario de menor tamaño, al utilizar subpalabras se pueden representar más palabras con menos tokens\n",
        "  - Permite capturar relaciones semánticas entre palabras, ya que las palabras relacionadas suelen tener la misma raíz o sufijos.\n",
        "\n",
        "- Notar que este tokenizador utiliza un mismo token como token \\<PAD\\> y token \\<EOS\\>, ¿por qué se puede hacer esto?\n",
        "\n",
        "> **Respuesta:**\n",
        "  Como GPT 2 no requiere de secuencias (inputs) de un largo determinado (mismo tamaño), entonces no necesita usar tokens de relleno (\\<PAD>) en el entrenamiento. Por lo tanto, GPT2 puede usar \\<PAD> o \\<EOS> para marcar el fin de la secuencia, si encuentra un \\<PAD> al medio de la oración, lo ignorará durante la inferencia. Esto es debido a que a diferencia de BERT, GPT no necesita en esa versión enmascaramiento, interpretandose el token de relleno/EOS como el final de una secuencia si esta al final y si esta entremedio como relleno.\n",
        "\n",
        "Se implementará una clase `Tokenizer` con una estructura similar a la implementada en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCYmBcAwhuzi"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = tiktoken.get_encoding('gpt2')\n",
        "        self.eos_id = 50256\n",
        "        self.pad_id = 50256\n",
        "\n",
        "    def encode(self, text):\n",
        "        return self.tokenizer.encode(text)\n",
        "\n",
        "    def decode(self, seq_ids):\n",
        "        return self.tokenizer.decode(seq_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1P41Dg_ru2w"
      },
      "source": [
        "### Dataset de entrenamiento\n",
        "\n",
        "Los datos de entrenamiento están almacenados en un archivo JSON, donde cada entrada es de la forma\n",
        "\n",
        "```\n",
        "{\n",
        "    \"instruction\": <texto con instrucciones>\n",
        "    \"input\":       <texto de entrada (opcional)>\n",
        "    \"output\":      <respuesta>\n",
        "}\n",
        "```\n",
        "\n",
        "La idea del IFT es continuar el entrenamiento de un modelo autorregresivo pre-entrenado (en este caso, se usará GPT 2), donde cada muestra de entrenamiento es una secuencia de texto que contiene:\n",
        "\n",
        "- **Instrucción:** contexto para el modelo. Aquí se le puede indicar que es un asistente que responde consultas hechas en el input.\n",
        "- **Input:** indica la _pregunta_ que el modelo debe responder. Muchas veces, el input es omitido ya que la pregunta se incluye en la instrucción.\n",
        "- **Output:** respuesta que se espera que entregue el modelo.\n",
        "\n",
        "Para entregarle esta información al modelo, es usual construir *instruction templates*, los cuales unen los 3 elementos en una única secuencia de tokens (*prompt*) con una estructura definida.\n",
        "\n",
        "- Implemente el método `format_input` en la clase `InstructionDataset` siguiendo el template Alpaca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1suuccyYB8KL"
      },
      "outputs": [],
      "source": [
        "class InstructionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, tokenizer):\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.encoded_sequences = []\n",
        "\n",
        "        for sample in self.data:\n",
        "            prompt, response = self.format_input(sample)\n",
        "            full_text = prompt + response\n",
        "            token_ids = tokenizer.encode(full_text)\n",
        "            token_ids.append(tokenizer.eos_id)\n",
        "            self.encoded_sequences.append(token_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        return self.encoded_sequences[n]\n",
        "\n",
        "    @staticmethod\n",
        "    def format_input(sample):\n",
        "        # Datos compuestos por instrucción, input, output/response\n",
        "        # Diseñar el PROMPT\n",
        "        # Prompt instruccion + input (opcional)\n",
        "        prompt = f\"Intrucción: \\n {sample['instruction']} \\n\\n\"\n",
        "        if input != None:\n",
        "            prompt += f\"Input: \\n {sample['input']} \\n\\n\"\n",
        "        prompt += \"Respuesta: \\n\"\n",
        "        response = sample['output']\n",
        "        return prompt, response\n",
        "\n",
        "# Revisar qué ocurre cuando tienes input en blanco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_stTo3Ukru2w"
      },
      "source": [
        "Se visualizarán algunos ejemplos de muestras que entrega `InstructionDataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-P16NTChuzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1826edf2-81d0-4642-82c6-5f66b405cc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño dataset: 1100\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Evaluate the following phrase by transforming it into the spelling given. \n",
            "\n",
            "Input: \n",
            " freind --> friend \n",
            "\n",
            "Respuesta: \n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Edit the following sentence for grammar. \n",
            "\n",
            "Input: \n",
            " He go to the park every day. \n",
            "\n",
            "Respuesta: \n",
            "He goes to the park every day.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Convert 45 kilometers to meters. \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "45 kilometers is 45000 meters.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk. \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "Although it was raining, they went for a walk.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " What are the first 10 square numbers? \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "1, 4, 9, 16, 25, 36, 49, 64, 81, 100.<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "dataset = InstructionDataset('data.json', tokenizer)\n",
        "\n",
        "print(f'Tamaño dataset:', len(dataset))\n",
        "\n",
        "for i in range(5):\n",
        "    print('-' * 100)\n",
        "    print(tokenizer.decode(dataset[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF-BQLlfru2x"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Dado que el entrenamiento se realiza utilizando batches de secuencias, todas las secuencias deben ser del mismo largo, por lo que las secuencias muy largas se truncan a un largo fijo, mientras que las secuencias muy cortas se extienden hasta el mismo largo fijo. En clases, este preprocesamiento se implementó dentro de la clase asociada al dataset. En este caso, el preprocesamiento se definirá al instanciar el dataloader usando una _collate function_ (función `collate_fn` implementada en la siguiente celda):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU46WjTpB8KM"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "    max_len = max(len(seq) for seq in batch)\n",
        "\n",
        "    padded_batch = []\n",
        "    for seq in batch:\n",
        "        if len(seq) < max_len:\n",
        "            seq = seq + [tokenizer.eos_id] * (max_len - len(seq))\n",
        "        else:\n",
        "            seq = seq[:max_len]\n",
        "        padded_batch.append(seq)\n",
        "\n",
        "    padded_tensor = torch.tensor(padded_batch, dtype=torch.long)\n",
        "\n",
        "    return padded_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJf7YcaiB8KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357eca68-8217-4651-cb19-48e8c4da3b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 49]) torch.Size([8, 68])\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Ejemplo:\n",
        "batch1 = next(iter(dataloader))\n",
        "batch2 = next(iter(dataloader))\n",
        "print(batch1.shape, batch2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMwIQKsWXNYx"
      },
      "source": [
        "- ¿Cuál es la principal ventaja de realizar este cambio?\n",
        "\n",
        ">**Respuesta:**\n",
        "  La principal ventaja de incorporar ``collate_fn`` personalizado en el DataLoader es que permite manejar de forma eficiente la variabilidad en el largo de las secuencias del dataset al momento de entrenar el modelo. Lo anterior se debe a que modelos como GPT-2 no aceptan secuencias de diferentes longitudes en un mismo batch, por lo que es necesario alinear todas las entradas. Esta función automatiza ese proceso con padding o truncando de forma flexible, según corresponda antes de alimentar el modelo con información.\n",
        "\n",
        "  Esto no solo mantiene el dataset limpio (sin necesidad de preprocesar y almacenar todo con padding fijo), sino que también permite una carga de datos más eficiente y adaptable, especialmente cuando se trabaja con datasets grandes como el caso anterior, con 1100 muestras.\n",
        "\n",
        "  Además, al asegurar que todas las secuencias dentro de un batch tengan el mismo largo, se habilita la paralelización efectiva en GPU, lo cual mejora significativamente la velocidad de entrenamiento. O sea, este cambio optimiza el rendimiento, mejora el uso de recursos y facilita el escalamiento del modelo hacia tareas más exigentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIqq9AKOhuzj"
      },
      "source": [
        "### Arquitectura GPT\n",
        "\n",
        "La siguiente celda contiene una implementación del modelo GPT 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTRuXt3oB8KO"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length),\n",
        "                                                diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        new_seq_length = queries.shape[2]\n",
        "        mask = torch.triu(torch.ones(new_seq_length, new_seq_length, device=x.device),\n",
        "                          diagonal=1).bool()\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores.masked_fill_(mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        attn_output = self.att(x)\n",
        "        x = self.drop_resid(attn_output)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_indices = torch.arange(seq_len, device=in_idx.device)\n",
        "        pos_embeds = self.pos_emb(pos_indices)\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        for block in self.trf_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n7foQP-ru2z"
      },
      "source": [
        "Notar que esta implementación tiene algunas diferencias menores con la implementación vista en clases. Por ejemplo, se realiza el cálculo de MHSA de forma directa (convencerse de que la clase `MultiHeadAttention` realiza lo esperado) y también se consideran términos de bias en las capas lineales (aunque trabajos posteriores muestran que no usar términos de bias estabiliza el entrenamiento en modelos más grandes).\n",
        "\n",
        "Se inicializará el modelo GPT 2 con los parámetros descargados anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y5OL7Dghuzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e147d4b-9348-475a-f8cf-b755ffbcd56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de parámetros: 406.3 millones.\n"
          ]
        }
      ],
      "source": [
        "# Arquitectura GPT:\n",
        "\n",
        "cfig = {'vocab_size': 50257,\n",
        " 'context_length': 1024,\n",
        " 'drop_rate': 0.0,\n",
        " 'qkv_bias': True,\n",
        " 'emb_dim': 1024,\n",
        " 'n_layers': 24,\n",
        " 'n_heads': 16}\n",
        "\n",
        "gpt = GPTModel(cfig)\n",
        "gpt.to(DEVICE)\n",
        "\n",
        "# Inicialización:\n",
        "params = torch.load('gpt2.pt', map_location=DEVICE)\n",
        "gpt.load_state_dict(params)\n",
        "\n",
        "# Cantidad de parámetros:\n",
        "n_params = sum(param.numel() for param in gpt.parameters()) / 1e6\n",
        "print(f'Cantidad de parámetros: {n_params:.4} millones.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjjM7zXYhuzo"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "Para el entrenamiento (fine tuning) se utilizará el mismo loop definido en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OCeHErnru20"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, dataloader, epochs, ckpt_filename):\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    pad_id = dataloader.dataset.tokenizer.pad_id\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
        "\n",
        "    training = {'losses': [], 'model': None}\n",
        "\n",
        "    try:\n",
        "        progressbar = tqdm.trange(epochs)\n",
        "        for epoch in progressbar:\n",
        "\n",
        "            for seq_batch in dataloader:\n",
        "\n",
        "                seq_batch = seq_batch.to(DEVICE)\n",
        "                x_batch, y_batch = seq_batch[:, :-1], seq_batch[:, 1:]\n",
        "\n",
        "                logits = model(x_batch)\n",
        "\n",
        "                batch_size, seq_length, vocab_size = logits.shape\n",
        "                logits = logits.reshape(batch_size * seq_length, vocab_size)\n",
        "                y_batch = y_batch.reshape(batch_size * seq_length)\n",
        "\n",
        "                loss = loss_fn(logits, y_batch)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                training['losses'].append(loss.item())\n",
        "                progressbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Entrenamiento interrumpido.')\n",
        "\n",
        "    training['model'] = model.state_dict()\n",
        "    torch.save(training, ckpt_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-onQxRXNYz"
      },
      "source": [
        "Se entrenará el modelo sobre el dataset definido anteriormente. Para esto, se usará, como es usual, el optimizador Adam:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3dalQJvhuzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97d677d-48de-40fd-cf4c-643f969cf003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [02:15<00:00, 67.96s/it, loss=0.663]\n"
          ]
        }
      ],
      "source": [
        "gpt_optimizer = optim.AdamW(gpt.parameters())\n",
        "train_model(gpt, gpt_optimizer, dataloader, epochs=2, ckpt_filename='gpt2_ift.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwSJZ-9Whuzo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e65d1020-a9b8-4614-ef84-9e313c529eb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "gpt_training = torch.load('gpt2_ift.pt', DEVICE, weights_only=True)\n",
        "gpt.load_state_dict(gpt_training['model'])\n",
        "\n",
        "plt.plot(gpt_training['losses'], label='train loss')\n",
        "plt.xlabel('Iteración')\n",
        "plt.ylabel('Entropía cruzada')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CylxOzsPru21"
      },
      "source": [
        "Notar que no se está considerando un dataset de evaluación, lo cual es imprescindible para evaluar el overfitting del modelo. En esta tarea se omitirá la evaluación por simplicidad, pero es importante tener presente que siempre debe realizarse en proyectos reales.\n",
        "\n",
        "- ¿Por qué es malo para un LLM que se produzca overfitting?\n",
        "\n",
        "> **Respuesta:**\n",
        "  Un modelo con overfitting repetiría las mismas secuencias/tokens, quitándole sentido a la predicción. Lo anterior implica que el modelo perderá capacidad del generalización y adaptación. Perderpa la creatividad (búsqueda nuevas rutas), lo que le impedirá generar secuencias levemente o muy diferentes. Es importante recordar que el overfitting implica tener un buen rendimiento en el conjunto de entrenamiento pero no en el de validación.\n",
        "\n",
        "- ¿De qué forma se puede evaluar un LLM?\n",
        "\n",
        "> **Respuesta:**\n",
        "  Depende del tipo de LLM que quiero evaluar, por ejemplo BERT, que utiliza un enfoque de masked language modeling, se podría enmascarar un token y comprobar su output, es decir si el modelo puede predecirlo bien.\n",
        "  En cambio en modelos autorregresivos como GPT, se pueden utilizar medidas de comparación de rendimiento tales como Perplexicity, evaluando que tan bien predice el modelo las secuencias posteriores. Una menor perplejidad representa que el modelo esta prediciendo mejor las secuencias y viceversa, siendo igual 1 si la predicción es perfecta. También existen otras formas de evaluación como BLEU/ROUGE que comparan n-gramas con textos de referencia.\n",
        "  Para la evaluación de generación \"creativa\" se realizan evaluaciones humanas de especialistas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE1F1tWUhuzo"
      },
      "source": [
        "### Generación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Nz3Oetru21"
      },
      "source": [
        "Teniendo el modelo entrenado, se puede utilizar para hacer inferencia. El loop de generación que se usará es el mismo que se vio en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZV6q6OaaOvg"
      },
      "outputs": [],
      "source": [
        "def generate_tokens(model, context, tokenizer, temperature=1, top_k=50, max_tokens=512, repetition_penalty=1):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    seq_id = tokenizer.encode(context)\n",
        "    seq_id = torch.tensor(seq_id, device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            logits = model(seq_id.unsqueeze(0))[0, -1, :]\n",
        "\n",
        "            if temperature == 0:\n",
        "                next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            else:\n",
        "                logits = logits / temperature\n",
        "\n",
        "                token_counts = torch.bincount(seq_id, minlength=logits.size(0))\n",
        "                for token_id, count in enumerate(token_counts):\n",
        "                    if count > 0:\n",
        "                        logits[token_id] /= (repetition_penalty ** count)\n",
        "\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "                probs = top_k_logits.softmax(dim=-1)\n",
        "                next_token = top_k_indices[torch.multinomial(probs, num_samples=1)]\n",
        "\n",
        "            seq_id = torch.cat((seq_id, next_token), dim=0)\n",
        "\n",
        "            if next_token in (tokenizer.eos_id, tokenizer.pad_id):\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(seq_id.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB6SMpQdru21"
      },
      "source": [
        "Para evaluar cualitativamente el entrenamiento, se comparará la respuesta generada por el modelo con la respuesta real utilizando una muestra del train set. Notar que el modelo puede estar sobreajustado, por lo que puede haber memorizado la respuesta. Sin embargo, en esta tarea no nos preocuparemos de eso (para evitar overfitting, basta con entrenar sobre más datos y durante más tiempo, siguiendo las leyes de escala de los LLMs).\n",
        "\n",
        "- Ajuste los hiperparámetros de generación (`temperature`, `top_k`, `max_tokens` y `repetition_penalty`) para obtener resultados aceptables. Proponga una hipótesis de por qué los hiperparámetros elegidos generan buenos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA_il9UQD5EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6198c3-d824-4086-93ee-5c939e9e9592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intrucción: \n",
            " What is the capital of Brazil? \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "The capital of Brazil is Brasília. \n",
            "\n",
            "\n",
            "Respuesta: \n",
            "\n",
            "The capital of Brazil is Brasília. <|endoftext|>\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESPUESTA REAL: The capital of Brazil is Brasília.\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.7\n",
        "top_k = 50\n",
        "max_tokens = 80\n",
        "repetition_penalty = 1.2\n",
        "\n",
        "i = torch.randint(100, size=[1]).item()\n",
        "\n",
        "prompt, real_response = dataset.format_input(dataset.data[i])\n",
        "output = generate_tokens(gpt, prompt, dataset.tokenizer, temperature, top_k, max_tokens, repetition_penalty)\n",
        "\n",
        "print(output)\n",
        "print(\"-\" * 80 + \"\\n\")\n",
        "print(f'RESPUESTA REAL: {real_response}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROPONER HIPOTESIS HIPERPARAMETROS ELEGIDOS\n",
        "A priori la temperatura junto a la repetition_penalty juegan cierto papel de poda, por parte de la temperatura forzamos al modelo a que sea más lógico utilizando los tokens de mayor probabilidad al disminuir la misma, mientras que la repetición por penalización regulariza haciendo mas cuadrada la distribución de forma local en los tokens de meyor proabilidad. El top k corresponde al parámetro más poderoso, ya que, voy a elegir de la ditribución como tal trozos con mayor o menor probabilidad"
      ],
      "metadata": {
        "id": "J8qL8uBHSPhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.randint(100, size=[1]).item()\n",
        "print(i)\n",
        "dataset.data[i]"
      ],
      "metadata": {
        "id": "JB1figwIpOPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cf1dd2-4956-4f56-f65b-fecaf0c0f76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Name the process by which water changes from liquid to gas.',\n",
              " 'input': '',\n",
              " 'output': 'The process by which water changes from liquid to gas is called evaporation.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmMgT_Ugru22"
      },
      "source": [
        "## Parte 3 (KV caching)\n",
        "\n",
        "En clases se revisó la técnica de KV caching, la cual modifica la implementación de un modelo para poder realizar el cálculo de atención de manera más eficiente durante la inferencia. Esta técnica consiste en almacenar temporalmente los vectores de key y value de los tokens procesados anteriormente para así no tener que calcular las proyecciones $K$ y $V$ necesarias para el cálculo de atención.\n",
        "\n",
        "En esta pregunta se debe modificar el código anterior para habilitar la opción de hacer KV caching. Para esto, se sugiere lo siguiente:\n",
        "- Modificar los módulos de la arquitectura GPT para que el modelo pueda recibir vectores de key y value calculados anteriormente y, así, utilizarlo en el cálculo de atención. De esta forma, el modelo debería retornar una tupla de la forma `output, (keys, values)`, donde `output` es la salida original del modelo (lo que retorna actualmente) y `(keys, values)` son las matrices de query y value actualizadas (se agrega una fila con los vectores recién calculados).\n",
        "- Modificar la función `generate_tokens` para que realice la generación utilizando la técnica de KV caching utilizando las matrices `(keys, values)` que se van actualizando en cada iteración.\n",
        "\n",
        "Notar que KV caching no se utiliza durante el entrenamiento. Por otro lado, es importante ver que solo es necesario modificar los métodos `forward` de algunos módulos y no los métodos `__init__`. En particular, esto no alterará la cantidad de parámetros, por lo que se puede cargar el modelo entrenado en la pregunta anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft8lSg7Sru22"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask',\n",
        "                             torch.triu(torch.ones(context_length, context_length),\n",
        "                                        diagonal=1))\n",
        "\n",
        "    def forward(self, x, past_key_value=None):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Si hay valores anteriores, los concatenamos\n",
        "        if past_key_value is not None:\n",
        "            past_k, past_v = past_key_value\n",
        "            keys = torch.cat((past_k, keys), dim=2)\n",
        "            values = torch.cat((past_v, values), dim=2)\n",
        "\n",
        "\n",
        "        new_seq_length = queries.shape[2]\n",
        "        mask = torch.triu(torch.ones(new_seq_length, new_seq_length, device=x.device),\n",
        "                          diagonal=1).bool()\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores.masked_fill_(mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        output=context_vec\n",
        "\n",
        "        return output, (keys, values)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x, past_key_value=None):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # tener cuidado, ahora las multihead retornan tanto los outputs como los\n",
        "        # key y values anteriores\n",
        "        attn_output, (keys, values) = self.att(x, past_key_value)\n",
        "\n",
        "        x = self.drop_resid(attn_output)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x, (keys, values)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx, past_key_value=None):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        pos_indices = torch.arange(seq_len, device=in_idx.device)\n",
        "        pos_embeds = self.pos_emb(pos_indices)\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        for i, block in enumerate(self.trf_blocks):\n",
        "          if past_key_value is not None:\n",
        "            past_key_value = past_key_value[i]\n",
        "          else:\n",
        "            past_key_value = None\n",
        "          x, (keys,values) = block(x, past_key_value=past_key_value)\n",
        "        # Guardamos inmediatamente los últimos keys y values\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        output = self.out_head(x)\n",
        "        return output, (keys, values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZL5qy5aIe1M"
      },
      "source": [
        "Se cargará el modelo entrenado sobre esta nueva arquitectura. Dado que no se cambió el número de parámetros, los pesos se pueden cargar sin problemas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiOgs2DSru22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2247b1d0-6ac1-498d-f1a4-45953774216d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Arquitectura GPT:\n",
        "gpt_kvcaching = GPTModel(cfig)\n",
        "gpt_kvcaching.to(DEVICE)\n",
        "\n",
        "# Carga del modelo entrenado:\n",
        "gpt_training = torch.load('gpt2_ift.pt', DEVICE, weights_only=True)\n",
        "gpt_kvcaching.load_state_dict(gpt_training['model'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3GubMdyItJD"
      },
      "source": [
        "Ahora se debe modificar la función `generate_tokens` para utilizar KV caching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXa_y7jpru22"
      },
      "outputs": [],
      "source": [
        "def generate_tokens_kvcaching(model, context, tokenizer, temperature=1,\n",
        "                              top_k=50, max_tokens=512, repetition_penalty=1):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    seq_id = tokenizer.encode(context)\n",
        "    seq_id = torch.tensor(seq_id, device=DEVICE)\n",
        "    past_key_value = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            logits, past_key_values = model(seq_id.unsqueeze(0), past_key_value)\n",
        "            logits = logits[0, -1, :]\n",
        "\n",
        "            if temperature == 0:\n",
        "                next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            else:\n",
        "                logits = logits / temperature\n",
        "\n",
        "                token_counts = torch.bincount(seq_id, minlength=logits.size(0))\n",
        "                for token_id, count in enumerate(token_counts):\n",
        "                    if count > 0:\n",
        "                        logits[token_id] /= (repetition_penalty ** count)\n",
        "\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "                probs = top_k_logits.softmax(dim=-1)\n",
        "                next_token = top_k_indices[torch.multinomial(probs, num_samples=1)]\n",
        "\n",
        "            seq_id = torch.cat((seq_id, next_token), dim=0)\n",
        "\n",
        "            if next_token in (tokenizer.eos_id, tokenizer.pad_id):\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(seq_id.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H573UriI3Sz"
      },
      "source": [
        "Para ver la diferencia, se generarán muestras utilizando ambos modelos (sin KV caching y con KV caching). Si las cosas quedaron bien implementadas, debería haber una diferencia significativa de rendimiento, la cual se vuelve más notoria a medida que aumenta el largo de las secuencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OztcRhdsHrZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ebbf85-bf6c-4fbe-c62d-99be95c63045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Frecuencia de generación (sin KV caching): 1.9873 tokens/segundo]\n",
            "[Frecuencia de generación (con KV caching): 1.9428 tokens/segundo]\n"
          ]
        }
      ],
      "source": [
        "i = torch.randint(100, size=[1]).item()\n",
        "\n",
        "prompt, _ = dataset.format_input(dataset.data[i])\n",
        "\n",
        "# # Sin KV caching:\n",
        "start_time = time.time()\n",
        "output = generate_tokens(gpt, prompt, dataset.tokenizer, max_tokens=64)\n",
        "end_time = time.time()\n",
        "generation_frequency = (len(output) - len(prompt)) / (end_time - start_time)\n",
        "print(f'[Frecuencia de generación (sin KV caching): {generation_frequency:.4f} tokens/segundo]')\n",
        "\n",
        "# Usando KV caching:\n",
        "start_time = time.time()\n",
        "output = generate_tokens_kvcaching(gpt_kvcaching, prompt, dataset.tokenizer, max_tokens=64)\n",
        "end_time = time.time()\n",
        "generation_frequency = (len(output) - len(prompt)) / (end_time - start_time)\n",
        "print(f'[Frecuencia de generación (con KV caching): {generation_frequency:.4f} tokens/segundo]')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}