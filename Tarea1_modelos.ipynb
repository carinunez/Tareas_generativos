{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APEcMpP3ru2r"
      },
      "source": [
        "# Tarea 1: Modelos Autorregresivos\n",
        "\n",
        "### MDS7203 Modelos Generativos Profundos\n",
        "\n",
        "**Nombre:**\n",
        "- Carolina Nuñez\n",
        "- Hecmar Taucare\n",
        "\n",
        "**Fecha de entrega:**\n",
        "\n",
        "Dado que la arquitectura Transformer es una de las dos arquitecturas específicas que se verán a lo largo del curso (la otra es la arquitectura U-Net), es importante asegurarse de entenderla bien. Por este motivo, esta primera tarea tendrá varias preguntas conceptuales que buscan evaluar si se entienden bien algunos detalles importantes de la arquitectura Transformer.\n",
        "\n",
        "Algunas instrucciones generales:\n",
        "- Se pueden utilizar de manera libre herramientas como ChatGPT y Claude, entre otras.\n",
        "- Para la entrega, no es necesario un informe, este archivo es suficiente.\n",
        "- Se debe entregar el documento con todas las celdas ejecutadas.\n",
        "- Se recomienda correr la tarea en GPU (usando Google Colab o una GPU local).\n",
        "- La tarea tiene 3 partes, y cada parte vale lo mismo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDFZAn8Qru2t"
      },
      "source": [
        "## Parte 1 (preguntas conceptuales)\n",
        "\n",
        "### Modelos autorregresivos generales\n",
        "- ¿Qué son los tokens especiales dentro de un vocabulario? Nombre al menos 5 junto a su función.\n",
        "> **Respuesta:**\n",
        "  Tokens especiales: son tokens añadidos durante el proceso de tokenización para cumplir un a función en particular, y son utilizados como marcadores.\n",
        "  1. **\\<PAD>** : utilizado como \"relleno\", para forzar el largo de una secuencia cuando no se logra el tamaño adecuado.\n",
        "  2. **\\<BOS>** : token agregado al inicio de cada secuencia\n",
        "  3. **\\<EOS>** : token agregado al final de cada secuencia\n",
        "  4. **\\<UNK>** : utilizado para representar tokens desconocidos,ie. fuera del vocabulario extendido.\n",
        "  5. **\\<MASK>** : utilizado para enmascarar/tapar un token. Se suele utilizar en BERT.\n",
        "\n",
        "- Los modelos autorregresivos se entrenan siguiendo el enfoque de máxima verosimilitud. Sin embargo, durante el entrenamiento, es usual normalizar la verosimilitud de una secuencia por su largo, ¿por qué se hace esto?\n",
        "> **Respuesta:**\n",
        "Como la log verosimilitud se define como una suma, las secuencias de mayor longitud dominarían esta función, entonces para evitar este problema se normaliza por el largo de la secuencia, de esa forma dos maneras de responder a cierta pregunta de forma correcta serían igual de buenas para el modelo, sin priorizar una por sobre otra, porque en una frase mas larga tengo más probabilidad de equivocarme, pero no por eso significa que la respuesta de la secuencia correcta larga sea \"peor\" aunque sea igual de bueno dado que ocupa más\n",
        "carácteres.\n",
        "\n",
        "\n",
        "- ¿Por qué los modelos neuronales por lo general no aplican la función Softmax en la salida, incluso cuando se está buscando aprender un vector de probabilidades (que permite definir una distribución sobre el vocabulario para predecir el siguiente token)? ¿Cómo se relaciona esto con la idea de temperatura usada durante la inferencia?\n",
        "> **Respuesta:**\n",
        "La función Softmax se incluye de forma implícita dentro de la función de pérdida crossentropy, ya que, la salida de la entropia cruzada corresponde\n",
        "a un output de probabilidad, además no se incluye porque o sino se estaría utilizando dos veces si es que en capas intermedias ya es una probabilidad (en los bloques de selfattention. Es por esto que nacen ciertas medidas de normalización, tanto para mejorar la estabilidad del modelo como para tener una salida de probabilidad más flexible, la temperatura es una de estas, en la cual a menor valor de temperatura *(T<1)*  se seleccionaran las secuencias que mayor probabilidad tienen de ser las correctas dadas las secuencias anteriores (menor dispersión en la distribución de tokens) , es decir el top de las mejores, mientras que con mayor temperatura *(T>1)* se le da mayor \"creatividad\" al modelo al elegir secuencias secundarias *(mayor dispersión en la probabilidad de tokens)*, pero que son buenas respuestas. Además no aplicar la softmax resulta más eficiente y estable, porque o sino en la optimización el modelo podría explotar o no converger a un mínimo local aceptable\n",
        "\n",
        "\n",
        "- ¿Cuál es la función de la temperatura al generar secuencias? ¿Qué diferencia hay entre una temperatura alta y una temperatura baja?\n",
        "> **Respuesta:**\n",
        "\n",
        "La **temperatura** es un parámetro que ajusta la aleatoriedad de las predicciones del modelo durante la generación de texto. Se aplica a los *logits* antes de usar la función *softmax*.\n",
        "\n",
        "$$\n",
        "P_i = \\frac{e^{z_i / T}}{\\sum_j e^{z_j / T}}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $( z_i )$: logit del token \\( i \\)  \n",
        "- $( T)$: temperatura (escala)  \n",
        "- $( P_i)$: probabilidad del token \\( i \\)\n",
        "\n",
        "**Interpretación del efecto de T:**\n",
        "\n",
        "- Si \\( T = 1 \\), se usa softmax normal.  \n",
        "- Si \\( T < 1 \\), la distribución se vuelve más “picuda” → más determinismo (elige los tokens más probables al ser mas concentrada).  \n",
        "- Si \\( T > 1 \\), la distribución se aplana → más creatividad (se exploran tokens menos probables).\n",
        "\n",
        "\n",
        "La temperatura permite controlar que tan creativas o precisas serán las secuencias creadas en la inferencia. Una temperatura alta le dará similar probabilidad a todos los tokens suavizando la distribución, mientras que una temperatura baja es bastante determinista pues se le da mayor peso a los tokens con mayor probabilidad *(concentrando o dandole mas peso a las secuencias que por si son las más probables de ser las mejores de todas)*, por lo que, en solicitudes de hacer poemas por ejemplo:\n",
        "La temperatura alta servirá para ajustar la respuesta al elegir secuencias secundarias --> mayor creatividad en labores artísticas.\n",
        "Mientras que para labores matemáticas el modelo tendrá la mejor solución posible a temperatura baja, dado que la matemática posee una lógica subyacente que es inalterable en la mayoria de los casos, tendiendo a una solución determinista\n",
        "\n",
        "\n",
        "### Arquitectura GPT\n",
        "- ¿Por qué se proyecta una misma entrada en 3 matrices ($Q$, $K$ y $V$) para el cálculo de atención? ¿Por qué no usar la propia entrada como vectores de query, key y value?\n",
        "> **Respuesta:**\n",
        "\n",
        "Antes de explicar lo anterior cabe destacar de que cada una de las matrices inician con pesos aleatorios, porque si fueran la misma matriz el modelo aprendería lo mismo. Cada una de estas posee cierta labor dentro del aprendizaje tanto del contexto de los tokens dentro del vocabulario, como la relación entre los tokens. Al multiplicar las matrices entre ellas,las cuales son resultado de entre ellas *(utilizando el producto punto como medida de similitud,)*, se pueden observar relaciones entre tokens y al multiplicar las matrices se fuerza a que el modelo aprenda de la información en otra dimensión (proyección), distintas proyecciones implican diferentes relaciones y puntos de vista diferentes, al paralelizar lo anterior y usar varias capas de selfattention, el modelo puede aprender diferentes habilidades, tales como reconocer estructura gramatical, operaciones lógicas, formas en las que se relacionan las palabras y formas de responder.\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax} \\left( \\frac{Q K^\\top}{\\sqrt{p}} \\right) \\cdot V\n",
        "$$\n",
        "\n",
        "  Las tres matrices anteriores corresponden cada una a\n",
        "  Q Query(matriz de consulta)\n",
        "  K Key (clave)\n",
        "  V Value (valor)\n",
        "El producto punto entre\n",
        "Q y K permite medir la similitud entre tokens, y con eso se calcula qué tan relevante es cada token con respecto a los demás. El resultado de la atención se usa para ponderar los valores en V, lo anterior permite al modelo enfocarse directamente en enfocarse de forma dinámica a aprender en diferentes partes de la secuencia de forma paralela.\n",
        "Estas distintas proyecciones hacen que el modelo aprenda relaciones desde múltiples puntos de vista (gramática, sintaxis, semántica, etc.), especialmente cuando se usan múltiples cabezas de atención en paralelo.\n",
        "\n",
        "\n",
        "- Al hacer el cálculo de atención, ¿por qué se normaliza el producto punto por la dimensión de los vectores de query y key?\n",
        "> **Respuesta:**\n",
        "  Se normaliza para que no explote la optimización y para prevenir que valores muy altos junto a las dimensiones altas de los vectores key y query hagan que el aprendizaje sea difícil  además normalizamos porque esperamos ques que la varianza esté acotada, i.e los datos no tengan gran dispersión.\n",
        "  Al dividir  $\\sqrt{p}$\n",
        " , se reduce la varianza del producto escalar, estabilizando los valores antes del softmax y asegurando un entrenamiento más eficiente y estable.\n",
        "Esto permite que la atención funcione correctamente incluso con vectores de alta dimensión\n",
        "\n",
        "- ¿Cuál es la función del masking causal al calcular self-attention? ¿Por qué no se aplica masking causal en el modelo BERT? ¿Qué tipo de masking utiliza BERT?\n",
        "> **Respuesta:**\n",
        "La función del masking causal permite evitar que el token aprenda información futura y solo se entrene con información pasada, lo cual es útil para modelos autoregresivos como GPT. Esto se logra aplicando una máscara triangular inferior, que bloquea la atención hacia tokens posteriores, manteniendo la causalidad en la generación.\n",
        "\n",
        "En cambio, modelos como BERT, que son bidireccionales, no usan este tipo de máscara porque su objetivo es distinto. En vez de generar texto secuencialmente, BERT se entrena con una tarea llamada masked language modeling, donde se enmascaran tokens al azar dentro de la secuencia, y el modelo los predice usando tanto el contexto anterior como el posterior.\n",
        "Esto le permite aprender una representación más completa del texto, lo que lo hace útil para tareas como clasificación, QA o detección de entidades.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VQb3-Qru2u"
      },
      "source": [
        "## Parte 2 (instruction fine tuning)\n",
        "\n",
        "Esta parte tiene dos objetivos principales:\n",
        "- Entender cómo se realiza instruction fine tuning (IFT). Esto busca evaluar que se entiende el proceso de entrenamiento de un LLM.\n",
        "- Implementar KV caching para acelerar la inferencia de un LLM. Esto busca evaluar que se entiende el proceso de generación de un LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qGYiDPRXru2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6a002ada-9a2d-4a6f-f78f-917fb0916b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "import torch\n",
        "import time\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import json\n",
        "import tiktoken\n",
        "import gdown\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxVEk93ru2v"
      },
      "source": [
        "Se comenzará descargando los datos de entrenamiento y los parámetros de un modelo ya pre-entrenado (GPT 2):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OBv36uq3ru2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "collapsed": true,
        "outputId": "9c71b403-d8ce-4482-9428-d9ace9111cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wky_HjclMRrg92bQu-xSp86PrdxLzlZE\n",
            "To: /content/data.json\n",
            "100%|██████████| 204k/204k [00:00<00:00, 101MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM\n",
            "From (redirected): https://drive.google.com/uc?id=1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM&confirm=t&uuid=d244b0c0-3970-417a-a082-2eec79559a0c\n",
            "To: /content/gpt2.pt\n",
            "100%|██████████| 1.73G/1.73G [00:22<00:00, 75.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt2.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "datos = 'https://drive.google.com/file/d/1Wky_HjclMRrg92bQu-xSp86PrdxLzlZE/view?usp=share_link'\n",
        "output_path = 'data.json'\n",
        "gdown.download(datos, output_path, quiet=False,fuzzy=True)\n",
        "\n",
        "modelo = 'https://drive.google.com/file/d/1Xhh4G2HpR7vTsUx_-FmEfOt7OG9rD3wM/view?usp=share_link'\n",
        "output_path = 'gpt2.pt'\n",
        "gdown.download(modelo, output_path, quiet=False,fuzzy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmEvQ2qru2v"
      },
      "source": [
        "### Tokenización\n",
        "\n",
        "Para la tokenización, se utilizará la librería `tiktoken` desarrollada por OpenAI. Esta librería contiene el tokenizador usado por el modelo GPT 2, al cual se le aplicará instruction fine tuning.\n",
        "\n",
        "- ¿Cuál es el tokenizador que utiliza GPT 2? Indique sus principales ventajas sobre tokenizar palabra a palabra.\n",
        "\n",
        "> **Respuesta:**\n",
        "  GPT 2 utiliza BPE (Byte Pair Encoding), este algortimo agrupa letras generando subpalabras que suelen repetirse.\n",
        "  \\\\\n",
        "  VENTAJAS :\n",
        "  - Al no agrupar por palabras completas, se evita el problema de tener que lidiar con palabras nuevas que no estaban en el vocabulario.\n",
        "  - Vocabulario de menor tamaño, al utilizar subpalabras se pueden representar más palabras con menos tokens\n",
        "  - Permite capturar relaciones semánticas entre palabras, ya que las palabras relacionadas suelen tener la misma raíz.\n",
        "\n",
        "- Notar que este tokenizador utiliza un mismo token como token \\<PAD\\> y token \\<EOS\\>, ¿por qué se puede hacer esto?\n",
        "\n",
        "> **Respuesta:**\n",
        "\n",
        "  Como GPT 2 no requiere de secuencias (inputs) de un largo determinado (mismo tamaño), entonces no necesita usar tokens de relleno (\\<PAD>). Por lo tanto, GPT2 puede usar \\<PAD> o \\<EOS> para marcar el fin de la secuencia. Esto es debido a que a diferencia de BERT, GPT no necesita en esa versión enmascaramiento, interpretandose el token de relleno/EOS como el final de una secuencia si esta al final y si esta entremedio como relleno.\n",
        "\n",
        "Se implementará una clase `Tokenizer` con una estructura similar a la implementada en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GCYmBcAwhuzi"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = tiktoken.get_encoding('gpt2')\n",
        "        self.eos_id = 50256\n",
        "        self.pad_id = 50256\n",
        "\n",
        "    def encode(self, text):\n",
        "        return self.tokenizer.encode(text)\n",
        "\n",
        "    def decode(self, seq_ids):\n",
        "        return self.tokenizer.decode(seq_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1P41Dg_ru2w"
      },
      "source": [
        "### Dataset de entrenamiento\n",
        "\n",
        "Los datos de entrenamiento están almacenados en un archivo JSON, donde cada entrada es de la forma\n",
        "\n",
        "```\n",
        "{\n",
        "    \"instruction\": <texto con instrucciones>\n",
        "    \"input\":       <texto de entrada (opcional)>\n",
        "    \"output\":      <respuesta>\n",
        "}\n",
        "```\n",
        "\n",
        "La idea del IFT es continuar el entrenamiento de un modelo autorregresivo pre-entrenado (en este caso, se usará GPT 2), donde cada muestra de entrenamiento es una secuencia de texto que contiene:\n",
        "\n",
        "- **Instrucción:** contexto para el modelo. Aquí se le puede indicar que es un asistente que responde consultas hechas en el input.\n",
        "- **Input:** indica la _pregunta_ que el modelo debe responder. Muchas veces, el input es omitido ya que la pregunta se incluye en la instrucción.\n",
        "- **Output:** respuesta que se espera que entregue el modelo.\n",
        "\n",
        "Para entregarle esta información al modelo, es usual construir *instruction templates*, los cuales unen los 3 elementos en una única secuencia de tokens (*prompt*) con una estructura definida.\n",
        "\n",
        "- Implemente el método `format_input` en la clase `InstructionDataset` siguiendo el template Alpaca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1suuccyYB8KL"
      },
      "outputs": [],
      "source": [
        "class InstructionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, tokenizer):\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.encoded_sequences = []\n",
        "\n",
        "        for sample in self.data:\n",
        "            prompt, response = self.format_input(sample)\n",
        "            full_text = prompt + response\n",
        "            token_ids = tokenizer.encode(full_text)\n",
        "            token_ids.append(tokenizer.eos_id)\n",
        "            self.encoded_sequences.append(token_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        return self.encoded_sequences[n]\n",
        "\n",
        "    @staticmethod\n",
        "    def format_input(sample):\n",
        "        # Datos compuestos por instrucción, input, output/response\n",
        "        # Diseñar el PROMPT\n",
        "        # Prompt instruccion + input (opcional)\n",
        "        prompt = f\"Intrucción: \\n {sample['instruction']} \\n\\n\"\n",
        "        if input != None:\n",
        "            prompt += f\"Input: \\n {sample['input']} \\n\\n\"\n",
        "        prompt += \"Respuesta: \\n\"\n",
        "        response = sample['output']\n",
        "        return prompt, response\n",
        "\n",
        "# Revisar qué ocurre cuando tienes input en blanco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_stTo3Ukru2w"
      },
      "source": [
        "Se visualizarán algunos ejemplos de muestras que entrega `InstructionDataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J-P16NTChuzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454b38a0-81ce-4adb-c12c-d0cf2fea5ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño dataset: 1100\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Evaluate the following phrase by transforming it into the spelling given. \n",
            "\n",
            "Input: \n",
            " freind --> friend \n",
            "\n",
            "Respuesta: \n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Edit the following sentence for grammar. \n",
            "\n",
            "Input: \n",
            " He go to the park every day. \n",
            "\n",
            "Respuesta: \n",
            "He goes to the park every day.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Convert 45 kilometers to meters. \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "45 kilometers is 45000 meters.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk. \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "Although it was raining, they went for a walk.<|endoftext|>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intrucción: \n",
            " What are the first 10 square numbers? \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "1, 4, 9, 16, 25, 36, 49, 64, 81, 100.<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "dataset = InstructionDataset('data.json', tokenizer)\n",
        "\n",
        "print(f'Tamaño dataset:', len(dataset))\n",
        "\n",
        "for i in range(5):\n",
        "    print('-' * 100)\n",
        "    print(tokenizer.decode(dataset[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF-BQLlfru2x"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Dado que el entrenamiento se realiza utilizando batches de secuencias, todas las secuencias deben ser del mismo largo, por lo que las secuencias muy largas se truncan a un largo fijo, mientras que las secuencias muy cortas se extienden hasta el mismo largo fijo. En clases, este preprocesamiento se implementó dentro de la clase asociada al dataset. En este caso, el preprocesamiento se definirá al instanciar el dataloader usando una _collate function_ (función `collate_fn` implementada en la siguiente celda):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UU46WjTpB8KM"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "    max_len = max(len(seq) for seq in batch)\n",
        "\n",
        "    padded_batch = []\n",
        "    for seq in batch:\n",
        "        if len(seq) < max_len:\n",
        "            seq = seq + [tokenizer.eos_id] * (max_len - len(seq))\n",
        "        else:\n",
        "            seq = seq[:max_len]\n",
        "        padded_batch.append(seq)\n",
        "\n",
        "    padded_tensor = torch.tensor(padded_batch, dtype=torch.long)\n",
        "\n",
        "    return padded_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tJf7YcaiB8KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9436dece-313f-46f7-be0f-b4e158d13ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 63]) torch.Size([8, 55])\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Ejemplo:\n",
        "batch1 = next(iter(dataloader))\n",
        "batch2 = next(iter(dataloader))\n",
        "print(batch1.shape, batch2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMwIQKsWXNYx"
      },
      "source": [
        "- ¿Cuál es la principal ventaja de realizar este cambio?\n",
        "\n",
        ">**Respuesta:**\n",
        "La principal ventaja de incorporar el collate_fn personalizado en el DataLoader es que permite manejar de forma eficiente la variabilidad en el largo de las secuencias del dataset al momento de entrenar el modelo. Lo anterior se debe a que modelos como GPT-2 no aceptan secuencias de diferentes longitudes en un mismo batch, es necesario alinear todas las entradas. Esta función automatiza ese proceso agregando padding dinámico o truncando de forma flexible antes de alimentar el modelo con información, según corresponda, justo antes de alimentar el modelo.\n",
        "\n",
        "Esto no solo mantiene el dataset limpio (sin necesidad de preprocesar y almacenar todo con padding fijo), sino que también permite una carga de datos más eficiente y adaptable, especialmente cuando se trabaja con datasets grandes como el caso anterior, con 1100 muestras.\n",
        "\n",
        "Además, al asegurar que todas las secuencias dentro de un batch tengan el mismo tamaño (longitud), se habilita la paralelización efectiva en GPU, lo cual mejora significativamente la velocidad de entrenamiento. Osea, este cambio optimiza el rendimiento, mejora el uso de recursos y facilita el escalamiento del modelo hacia tareas más exigentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIqq9AKOhuzj"
      },
      "source": [
        "### Arquitectura GPT\n",
        "\n",
        "La siguiente celda contiene una implementación del modelo GPT 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aTRuXt3oB8KO"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length),\n",
        "                                                diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        new_seq_length = queries.shape[2]\n",
        "        mask = torch.triu(torch.ones(new_seq_length, new_seq_length, device=x.device),\n",
        "                          diagonal=1).bool()\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores.masked_fill_(mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        attn_output = self.att(x)\n",
        "        x = self.drop_resid(attn_output)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_indices = torch.arange(seq_len, device=in_idx.device)\n",
        "        pos_embeds = self.pos_emb(pos_indices)\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        for block in self.trf_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n7foQP-ru2z"
      },
      "source": [
        "Notar que esta implementación tiene algunas diferencias menores con la implementación vista en clases. Por ejemplo, se realiza el cálculo de MHSA de forma directa (convencerse de que la clase `MultiHeadAttention` realiza lo esperado) y también se consideran términos de bias en las capas lineales (aunque trabajos posteriores muestran que no usar términos de bias estabiliza el entrenamiento en modelos más grandes).\n",
        "\n",
        "Se inicializará el modelo GPT 2 con los parámetros descargados anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6Y5OL7Dghuzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347d89fc-9684-4003-f4e8-576008f071ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de parámetros: 406.3 millones.\n"
          ]
        }
      ],
      "source": [
        "# Arquitectura GPT:\n",
        "\n",
        "cfig = {'vocab_size': 50257,\n",
        " 'context_length': 1024,\n",
        " 'drop_rate': 0.0,\n",
        " 'qkv_bias': True,\n",
        " 'emb_dim': 1024,\n",
        " 'n_layers': 24,\n",
        " 'n_heads': 16}\n",
        "\n",
        "gpt = GPTModel(cfig)\n",
        "gpt.to(DEVICE)\n",
        "\n",
        "# Inicialización:\n",
        "params = torch.load('gpt2.pt', map_location=DEVICE)\n",
        "gpt.load_state_dict(params)\n",
        "\n",
        "# Cantidad de parámetros:\n",
        "n_params = sum(param.numel() for param in gpt.parameters()) / 1e6\n",
        "print(f'Cantidad de parámetros: {n_params:.4} millones.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjjM7zXYhuzo"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "Para el entrenamiento (fine tuning) se utilizará el mismo loop definido en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5OCeHErnru20"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, dataloader, epochs, ckpt_filename):\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    pad_id = dataloader.dataset.tokenizer.pad_id\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
        "\n",
        "    training = {'losses': [], 'model': None}\n",
        "\n",
        "    try:\n",
        "        progressbar = tqdm.trange(epochs)\n",
        "        for epoch in progressbar:\n",
        "\n",
        "            for seq_batch in dataloader:\n",
        "\n",
        "                seq_batch = seq_batch.to(DEVICE)\n",
        "                x_batch, y_batch = seq_batch[:, :-1], seq_batch[:, 1:]\n",
        "\n",
        "                logits = model(x_batch)\n",
        "\n",
        "                batch_size, seq_length, vocab_size = logits.shape\n",
        "                logits = logits.reshape(batch_size * seq_length, vocab_size)\n",
        "                y_batch = y_batch.reshape(batch_size * seq_length)\n",
        "\n",
        "                loss = loss_fn(logits, y_batch)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                training['losses'].append(loss.item())\n",
        "                progressbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Entrenamiento interrumpido.')\n",
        "\n",
        "    training['model'] = model.state_dict()\n",
        "    torch.save(training, ckpt_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-onQxRXNYz"
      },
      "source": [
        "Se entrenará el modelo sobre el dataset definido anteriormente. Para esto, se usará, como es usual, el optimizador Adam:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q3dalQJvhuzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7112e0e1-31c0-4fd0-de7e-06330b735adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [02:14<00:00, 67.03s/it, loss=0.602]\n"
          ]
        }
      ],
      "source": [
        "gpt_optimizer = optim.AdamW(gpt.parameters())\n",
        "train_model(gpt, gpt_optimizer, dataloader, epochs=2, ckpt_filename='gpt2_ift.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gwSJZ-9Whuzo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ab494957-d034-4475-8edc-4dac728ae0e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "gpt_training = torch.load('gpt2_ift.pt', DEVICE, weights_only=True)\n",
        "gpt.load_state_dict(gpt_training['model'])\n",
        "\n",
        "plt.plot(gpt_training['losses'], label='train loss')\n",
        "plt.xlabel('Iteración')\n",
        "plt.ylabel('Entropía cruzada')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CylxOzsPru21"
      },
      "source": [
        "Notar que no se está considerando un dataset de evaluación, lo cual es imprescindible para evaluar el overfitting del modelo. En esta tarea se omitirá la evaluación por simplicidad, pero es importante tener presente que siempre debe realizarse en proyectos reales.\n",
        "\n",
        "- ¿Por qué es malo para un LLM que se produzca overfitting?\n",
        "\n",
        "> **Respuesta:**\n",
        "  El modelo repetiría la misma secuencia, quitandole sentido a la predicción, lo anterior implica tanto que el modelo no podrá ser creativo (buscar nuevas rutas de conocimiento), por lo que no servirá por ejemplo para predecir secuencias levemente o muy diferentes teniendo falta de flexibilidad, recordar que el overfitting implica tener un buen rendimiento en el conjunto de entrenamiento pero no en el de validación (situación real al momento de utilizarlo)\n",
        "\n",
        "- ¿De qué forma se puede evaluar un LLM?\n",
        "\n",
        "> **Respuesta:**\n",
        "\n",
        "  Depende del tipo de LLM que quiero evaluar, por ejemplo BERT,utiliza un enfoque de masked language modeling, enmascarando un token y comprobando su output. es decir si el modelo puede predecirlo bien.\n",
        "  En cambio GPT, utiliza medidas de comparación de rendimiento tales como Perplexicity, evaluando que tan bien predice el modelo las secuencias posteriores, a menor perplexity representa que el modelo esta prediciendo mejor las secuencias y viceversa, con el valor de 1 en predicción perfecta. Para la evaluación de generación \"creativa\" se realizan evaluaciones humanas de especialistas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE1F1tWUhuzo"
      },
      "source": [
        "### Generación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Nz3Oetru21"
      },
      "source": [
        "Teniendo el modelo entrenado, se puede utilizar para hacer inferencia. El loop de generación que se usará es el mismo que se vio en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gZV6q6OaaOvg"
      },
      "outputs": [],
      "source": [
        "def generate_tokens(model, context, tokenizer, temperature=1, top_k=50, max_tokens=512, repetition_penalty=1):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    seq_id = tokenizer.encode(context)\n",
        "    seq_id = torch.tensor(seq_id, device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            logits = model(seq_id.unsqueeze(0))[0, -1, :]\n",
        "\n",
        "            if temperature == 0:\n",
        "                next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            else:\n",
        "                logits = logits / temperature\n",
        "\n",
        "                token_counts = torch.bincount(seq_id, minlength=logits.size(0))\n",
        "                for token_id, count in enumerate(token_counts):\n",
        "                    if count > 0:\n",
        "                        logits[token_id] /= (repetition_penalty ** count)\n",
        "\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "                probs = top_k_logits.softmax(dim=-1)\n",
        "                next_token = top_k_indices[torch.multinomial(probs, num_samples=1)]\n",
        "\n",
        "            seq_id = torch.cat((seq_id, next_token), dim=0)\n",
        "\n",
        "            if next_token in (tokenizer.eos_id, tokenizer.pad_id):\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(seq_id.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB6SMpQdru21"
      },
      "source": [
        "Para evaluar cualitativamente el entrenamiento, se comparará la respuesta generada por el modelo con la respuesta real utilizando una muestra del train set. Notar que el modelo puede estar sobreajustado, por lo que puede haber memorizado la respuesta. Sin embargo, en esta tarea no nos preocuparemos de eso (para evitar overfitting, basta con entrenar sobre más datos y durante más tiempo, siguiendo las leyes de escala de los LLMs).\n",
        "\n",
        "- Ajuste los hiperparámetros de generación (`temperature`, `top_k`, `max_tokens` y `repetition_penalty`) para obtener resultados aceptables. Proponga una hipótesis de por qué los hiperparámetros elegidos generan buenos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EA_il9UQD5EL",
        "outputId": "b5928779-bc36-4561-b562-09de8b832f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intrucción: \n",
            " Name the device that measures atmospheric pressure. \n",
            "\n",
            "Input: \n",
            "  \n",
            "\n",
            "Respuesta: \n",
            "The device that measures atmospheric pressure is the\n",
            "The device that measures air\n",
            "The device that measuring air is anemometer\n",
            "The device that measures water\n",
            "Input: \n",
            " The device of measuring water\n",
            "The device of measuring water\n",
            " The device that measure gas\n",
            " water\n",
            "The device of measuring water\n",
            " the device of measuring water\n",
            "It\n",
            " water\n",
            " The device to measure gas\n",
            " the water\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESPUESTA REAL: The device that measures atmospheric pressure is a barometer.\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.7\n",
        "top_k = 50\n",
        "max_tokens = 80\n",
        "repetition_penalty = 1.2\n",
        "\n",
        "i = torch.randint(100, size=[1]).item()\n",
        "\n",
        "prompt, real_response = dataset.format_input(dataset.data[i])\n",
        "output = generate_tokens(gpt, prompt, dataset.tokenizer, temperature, top_k, max_tokens, repetition_penalty)\n",
        "\n",
        "print(output)\n",
        "print(\"-\" * 80 + \"\\n\")\n",
        "print(f'RESPUESTA REAL: {real_response}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROPONER HIPOTESIS HIPERPARAMETROS ELEGIDOS"
      ],
      "metadata": {
        "id": "J8qL8uBHSPhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.randint(100, size=[1]).item()\n",
        "print(i)\n",
        "dataset.data[i]"
      ],
      "metadata": {
        "id": "JB1figwIpOPB",
        "outputId": "93a1b4c7-6356-438c-ea11-bac5080dbb6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Rewrite the sentence using a simile.',\n",
              " 'input': 'She is very graceful.',\n",
              " 'output': 'She is as graceful as a swan.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmMgT_Ugru22"
      },
      "source": [
        "## Parte 3 (KV caching)\n",
        "\n",
        "En clases se revisó la técnica de KV caching, la cual modifica la implementación de un modelo para poder realizar el cálculo de atención de manera más eficiente durante la inferencia. Esta técnica consiste en almacenar temporalmente los vectores de key y value de los tokens procesados anteriormente para así no tener que calcular las proyecciones $K$ y $V$ necesarias para el cálculo de atención.\n",
        "\n",
        "En esta pregunta se debe modificar el código anterior para habilitar la opción de hacer KV caching. Para esto, se sugiere lo siguiente:\n",
        "- Modificar los módulos de la arquitectura GPT para que el modelo pueda recibir vectores de key y value calculados anteriormente y, así, utilizarlo en el cálculo de atención. De esta forma, el modelo debería retornar una tupla de la forma `output, (keys, values)`, donde `output` es la salida original del modelo (lo que retorna actualmente) y `(keys, values)` son las matrices de query y value actualizadas (se agrega una fila con los vectores recién calculados).\n",
        "- Modificar la función `generate_tokens` para que realice la generación utilizando la técnica de KV caching utilizando las matrices `(keys, values)` que se van actualizando en cada iteración.\n",
        "\n",
        "Notar que KV caching no se utiliza durante el entrenamiento. Por otro lado, es importante ver que solo es necesario modificar los métodos `forward` de algunos módulos y no los métodos `__init__`. En particular, esto no alterará la cantidad de parámetros, por lo que se puede cargar el modelo entrenado en la pregunta anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ft8lSg7Sru22"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask',\n",
        "                             torch.triu(torch.ones(context_length, context_length),\n",
        "                                        diagonal=1))\n",
        "\n",
        "    def forward(self, x, past_key_value=None):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Si hay valores anteriores, los concatenamos\n",
        "        if past_key_value is not None:\n",
        "            past_k, past_v = past_key_value\n",
        "            keys = torch.cat((past_k, keys), dim=2)\n",
        "            values = torch.cat((past_v, values), dim=2)\n",
        "\n",
        "\n",
        "        new_seq_length = queries.shape[2]\n",
        "        mask = torch.triu(torch.ones(new_seq_length, new_seq_length, device=x.device),\n",
        "                          diagonal=1).bool()\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores.masked_fill_(mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return output, (keys, values)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x, past_key_value=None):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        attn_output, (keys, values) = self.att(x, past_key_value)\n",
        "\n",
        "        x = self.drop_resid(attn_output)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x, (keys, values)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx, past_key_values=None):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        pos_indices = torch.arange(seq_len, device=in_idx.device)\n",
        "        pos_embeds = self.pos_emb(pos_indices)\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        for block in self.trf_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        new_key_values = []\n",
        "        for i, block in enumerate(self.trf_blocks):\n",
        "          if past_key_values is not None:\n",
        "            past_kv = past_key_values[i]\n",
        "          else:\n",
        "            past_kv = None\n",
        "          x, actual_kv = block(x, past_kv=past_kv)\n",
        "          new_key_values.append(actual_kv)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        output = self.out_head(x)\n",
        "        return output, (keys, values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZL5qy5aIe1M"
      },
      "source": [
        "Se cargará el modelo entrenado sobre esta nueva arquitectura. Dado que no se cambió el número de parámetros, los pesos se pueden cargar sin problemas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qiOgs2DSru22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49289e19-512e-4c2b-c505-f6a3a9021a5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Arquitectura GPT:\n",
        "gpt_kvcaching = GPTModel(cfig)\n",
        "gpt_kvcaching.to(DEVICE)\n",
        "\n",
        "# Carga del modelo entrenado:\n",
        "gpt_training = torch.load('gpt2_ift.pt', DEVICE, weights_only=True)\n",
        "gpt_kvcaching.load_state_dict(gpt_training['model'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3GubMdyItJD"
      },
      "source": [
        "Ahora se debe modificar la función `generate_tokens` para utilizar KV caching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BXa_y7jpru22"
      },
      "outputs": [],
      "source": [
        "def generate_tokens_kvcaching(model, context, tokenizer, temperature=1,\n",
        "                              top_k=50, max_tokens=512, repetition_penalty=1):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    seq_id = tokenizer.encode(context)\n",
        "    seq_id = torch.tensor(seq_id, device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            logits = model(seq_id.unsqueeze(0))[0, -1, :]\n",
        "\n",
        "            if temperature == 0:\n",
        "                next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            else:\n",
        "                logits = logits / temperature\n",
        "\n",
        "                token_counts = torch.bincount(seq_id, minlength=logits.size(0))\n",
        "                for token_id, count in enumerate(token_counts):\n",
        "                    if count > 0:\n",
        "                        logits[token_id] /= (repetition_penalty ** count)\n",
        "\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "                probs = top_k_logits.softmax(dim=-1)\n",
        "                next_token = top_k_indices[torch.multinomial(probs, num_samples=1)]\n",
        "\n",
        "            seq_id = torch.cat((seq_id, next_token), dim=0)\n",
        "\n",
        "            if next_token in (tokenizer.eos_id, tokenizer.pad_id):\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(seq_id.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H573UriI3Sz"
      },
      "source": [
        "Para ver la diferencia, se generarán muestras utilizando ambos modelos (sin KV caching y con KV caching). Si las cosas quedaron bien implementadas, debería haber una diferencia significativa de rendimiento, la cual se vuelve más notoria a medida que aumenta el largo de las secuencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OztcRhdsHrZ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "0319366b-6049-4dfc-82a5-a0ed3421ed1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Frecuencia de generación (sin KV caching): 3.1599 tokens/segundo]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "dropout(): argument 'input' (position 1) must be Tensor, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-819911044064>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Usando KV caching:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_tokens_kvcaching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt_kvcaching\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgeneration_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a5166f63ee91>\u001b[0m in \u001b[0;36mgenerate_tokens_kvcaching\u001b[0;34m(model, context, tokenizer, temperature, top_k, max_tokens, repetition_penalty)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-77f8af4a84d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_idx, past_key_values)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrf_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mnew_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-77f8af4a84d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, past_key_value)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_resid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not str"
          ]
        }
      ],
      "source": [
        "i = torch.randint(100, size=[1]).item()\n",
        "\n",
        "prompt, _ = dataset.format_input(dataset.data[i])\n",
        "\n",
        "# Sin KV caching:\n",
        "start_time = time.time()\n",
        "output = generate_tokens(gpt, prompt, dataset.tokenizer, max_tokens=64)\n",
        "end_time = time.time()\n",
        "generation_frequency = (len(output) - len(prompt)) / (end_time - start_time)\n",
        "print(f'[Frecuencia de generación (sin KV caching): {generation_frequency:.4f} tokens/segundo]')\n",
        "\n",
        "# Usando KV caching:\n",
        "start_time = time.time()\n",
        "output = generate_tokens_kvcaching(gpt_kvcaching, prompt, dataset.tokenizer, max_tokens=64)\n",
        "end_time = time.time()\n",
        "generation_frequency = (len(output) - len(prompt)) / (end_time - start_time)\n",
        "print(f'[Frecuencia de generación (con KV caching): {generation_frequency:.4f} tokens/segundo]')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}